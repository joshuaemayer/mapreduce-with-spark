# MapReduce with Spark

# Background 

This mini-project will go through some basic exercises in PySpark (Python's interface to Spark) and MapReduce. In this exercise I imported text files that contained stop words and text to analyze.  The goal was to leverage Spark functions in order to isolate the most frequent words as well as filter and slice on the most frequent words. 